[TOC]
# Replica Set members   

A replica set in MongoDB is a group of mongod processes that provide redundancy and high availability. The members of a replica set are:

+ Primary   
    The primary receives all write operations.
+ Secondaries   
    Secondaries replicate operations from the primary to maintain an identical data set. Secondaries may have additional configurations for special usage profiles. For example, secondaries may be non-voting or priority 0.

The minimum recommended configuration for a replica set is a three member replica set with three data-bearing members: one primary and two secondary members. In some circumstances (such as you have a primary and a secondary but cost constraints prohibit adding another secondary), you may choose to include an arbiter. An arbiter participates in elections but does not hold data (i.e. does not provide data redundancy).

A replica set can have up to 50 members but only 7 voting members.

+ Primary 

The primary is the only member in the replica set that receives write operations. MongoDB applies write operations on the primary and then records the operations on the primary’s oplog. Secondary members replicate this log and apply the operations to their data sets.

In the following three-member replica set, the primary accepts all write operations. Then the secondaries replicate the oplog to apply to their data sets.

![avatar](https://docs.mongodb.com/manual/_images/replica-set-read-write-operations-primary.bakedsvg.svg)

All members of the replica set can accept read operations. However, by default, an application directs its read operations to the primary member. See Read Preference for details on changing the default read behavior.

The replica set can have at most one primary. [2] If the current primary becomes unavailable, an election determines the new primary. See Replica Set Elections for more details.

+ Secondaries 

A secondary maintains a copy of the primary’s data set. To replicate data, a secondary applies operations from the primary’s oplog to its own data set in an asynchronous process. [1] A replica set can have one or more secondaries.

The following three-member replica set has two secondary members. The secondaries replicate the primary’s oplog and apply the operations to their data sets.

![avatar](https://docs.mongodb.com/manual/_images/replica-set-primary-with-two-secondaries.bakedsvg.svg)

Although clients cannot write data to secondaries, clients can read data from secondary members. See Read Preference for more information on how clients direct read operations to replica sets.

A secondary can become a primary. If the current primary becomes unavailable, the replica set holds an election to choose which of the secondaries becomes the new primary.

See Replica Set Elections for more details.

You can configure a secondary member for a specific purpose. You can configure a secondary to:

+ Prevent it from becoming a primary in an election, which allows it to reside in a secondary data center or to serve as a cold standby. See Priority 0 Replica Set Members.

+ Prevent applications from reading from it, which allows it to run applications that require separation from normal traffic. See Hidden Replica Set Members.

+ Keep a running “historical” snapshot for use in recovery from certain errors, such as unintentionally deleted databases. See Delayed Replica Set Members.

+ Arbiter     

In some circumstances (such as you have a primary and a secondary but cost constraints prohibit adding another secondary), you may choose to add an arbiter to your replica set. An arbiter does not have a copy of data set and cannot become a primary. However, an arbiter participates in elections for primary. An arbiter has exactly 1 election vote.

Changed in version 3.6: Starting in MongoDB 3.6, arbiters have priority 0. When you upgrade a replica set to MongoDB 3.6, if the existing configuration has an arbiter with priority 1, MongoDB 3.6 reconfigures the arbiter to have priority 0.

```
IMPORTANT
Do not run an arbiter on systems that also host the primary or the secondary members of the replica set.
```

To add an arbiter, see Add an Arbiter to Replica Set.

For considerations when using an arbiter, see Replica Set Arbiter.

## Replica Set Primary 

The primary is the only member in the replica set that receives write operations. MongoDB applies write operations on the primary and then records the operations on the primary’s oplog. Secondary members replicate this log and apply the operations to their data sets.

In the following three-member replica set, the primary accepts all write operations. Then the secondaries replicate the oplog to apply to their data sets.

![avatar](https://docs.mongodb.com/manual/_images/replica-set-read-write-operations-primary.bakedsvg.svg)

All members of the replica set can accept read operations. However, by default, an application directs its read operations to the primary member. See Read Preference for details on changing the default read behavior.

The replica set can have at most one primary. [1] If the current primary becomes unavailable, an election determines the new primary. See Replica Set Elections for more details.

In the following 3-member replica set, the primary becomes unavailable. This triggers an election which selects one of the remaining secondaries as the new primary.

![avatar](https://docs.mongodb.com/manual/_images/replica-set-trigger-election.bakedsvg.svg)

## Replica Set Secondary Members

A secondary maintains a copy of the primary’s data set. To replicate data, a secondary applies operations from the primary’s oplog to its own data set in an asynchronous process. [1] A replica set can have one or more secondaries.

The following three-member replica set has two secondary members. The secondaries replicate the primary’s oplog and apply the operations to their data sets.

![avatar](https://docs.mongodb.com/manual/_images/replica-set-primary-with-two-secondaries.bakedsvg.svg)

Although clients cannot write data to secondaries, clients can read data from secondary members. See Read Preference for more information on how clients direct read operations to replica sets.

A secondary can become a primary. If the current primary becomes unavailable, the replica set holds an election to choose which of the secondaries becomes the new primary.

In the following three-member replica set, the primary becomes unavailable. This triggers an election where one of the remaining secondaries becomes the new primary.

![avatar](https://docs.mongodb.com/manual/_images/replica-set-trigger-election.bakedsvg.svg)

See Replica Set Elections for more details.

You can configure a secondary member for a specific purpose. You can configure a secondary to:

+ Prevent it from becoming a primary in an election, which allows it to reside in a secondary data center or to serve as a cold standby. See Priority 0 Replica Set Members.
+ Prevent applications from reading from it, which allows it to run applications that require separation from normal traffic. See Hidden Replica Set Members.
+ Keep a running “historical” snapshot for use in recovery from certain errors, such as unintentionally deleted databases. See Delayed Replica Set Members.

### Priority 0 Replica Set Members

A priority 0 member is a member that cannot become primary and cannot trigger elections. Priority 0 members can acknowledge write operations issued with write concern of w : <number>. For "majority" write concern, the priority 0 member must also be a voting member (i.e. members[n].votes is greater than 0) to acknowledge the write. Non-voting replica set members (i.e. members[n].votes is 0) cannot contribute to acknowledging write operations with "majority" write concern.

Other than the aforementioned restrictions, secondaries that have priority 0 function as normal secondaries: they maintain a copy of the data set, accept read operations, and vote in elections.

Configuring a replica set member with priority 0 might be desired if the particular member is deployed in a data center that is distant from the main deployment and therefore has higher latency. It may serve local read requests well, but might not be an ideal candidate to perform the duties of a primary due to its latency.

For this situation, the following diagram shows a data center on the left which hosts the primary and a secondary, and a data center on the right which hosts a secondary that has been configured to have priority 0 to prevent it from becoming primary. Because of this setting, only the members in the left data center are eligible to become primary in an election.

![avatar](https://docs.mongodb.com/manual/_images/replica-set-three-members-geographically-distributed.bakedsvg.svg)

Compare this to the default priority for replica set members, priority 1, where either of the secondaries in this scenario would be eligible to serve as primary. See Replica Sets Distributed Across Two or More Data Centers for more information.

+ **Priority 0 Members as Standbys**

    A secondary with priority 0 can function as a standby. In some replica sets, it might not be possible to add a new member in a reasonable amount of time. A standby member keeps a current copy of the data to be able to replace an unavailable member.

    In many cases, you need not set standby to priority 0. However, in replica sets with varied hardware or geographic distribution, a priority 0 standby ensures that only certain members become primary.

    A priority 0 standby may also be valuable for some members of a set with different hardware or workload profiles. In these cases, deploy a member with priority 0 so it can’t become primary. Also consider using an hidden member for this purpose.

    If your set already has seven voting members, also configure the member as non-voting.

+ **Failover Considerations**

    When configuring a secondary to have priority 0, consider potential failover patterns, including all possible network partitions. Always ensure that your main data center contains both a quorum of voting members and members that are eligible to be primary.

+ Example    
    To configure a secondary to have priority 0, see Prevent Secondary from Becoming Primary.

### Hidden Replica Set Members  
A hidden member maintains a copy of the primary’s data set but is invisible to client applications. Hidden members are good for workloads with different usage patterns from the other members in the replica set. Hidden members must always be priority 0 members and so cannot become primary. The db.isMaster() method does not display hidden members. Hidden members, however, may vote in elections.

In the following five-member replica set, all four secondary members have copies of the primary’s data set, but one of the secondary members is hidden.

![avatar](https://docs.mongodb.com/manual/_images/replica-set-hidden-member.bakedsvg.svg)

+ **Behavior**
    * *Read Operations*     
        Clients will not distribute reads with the appropriate read preference to hidden members. As a result, these members receive no traffic other than basic replication. Use hidden members for dedicated tasks such as reporting and backups. Delayed members should be hidden.

        In a sharded cluster, mongos do not interact with hidden members.

+ **Voting**    
    Hidden members may vote in replica set elections. If you stop a voting hidden member, ensure that the set has an active majority or the primary will step down.

    For the purposes of backups,db.fsyncLock() ensures that the data files are safe to copy using low-level backup utilities such as cp, scp, or tar. A mongod started using the copied files contains user-written data that is indistinguishable from the user-written data on the locked mongod.

+ The data files of a locked mongod may change due to operations such as journaling syncs or WiredTiger snapshots. While this has no affect on the logical data (e.g. data accessed by clients), some backup utilities may detect these changes and emit warnings or fail with errors. For more information on MongoDB- recommended backup utilities and procedures, see MongoDB Backup Methods.

+ **Write Concern**
Hidden replica set members can acknowledge write operations issued with w: <number>. For write operations isued with w : "majority", however, hidden members must also be voting members (i.e. members[n].votes greater than 0) to acknowledge the "majority" write operation. Non-voting replica set members (i.e. members[n].votes is 0) cannot contribute to acknowledging write operations with majority write concern.

+ **Further Reading**
For more information about backing up MongoDB databases, see MongoDB Backup Methods. To configure a hidden member, see Configure a Hidden Replica Set Member.

### Delayed Replica Set Members

Delayed members contain copies of a replica set’s data set. However, a delayed member’s data set reflects an earlier, or delayed, state of the set. For example, if the current time is 09:52 and a member has a delay of an hour, the delayed member has no operation more recent than 08:52.

Because delayed members are a “rolling backup” or a running “historical” snapshot of the data set, they may help you recover from various kinds of human error. For example, a delayed member can make it possible to recover from unsuccessful application upgrades and operator errors including dropped databases and collections.

+ **Considerations**
    * *Requirements* 
        Delayed members:
        - Must be priority 0 members. Set the priority to 0 to prevent a delayed member from becoming primary.
        - Should be hidden members. Always prevent applications from seeing and querying delayed members.
        - do vote in elections for primary, if members[n].votes is set to 1.

+ **Behavior**
Delayed members copy and apply operations from the source oplog on a delay. When choosing the amount of delay, consider that the amount of delay:

+ must be equal to or greater than your expected maintenance window durations.
+ must be smaller than the capacity of the oplog. For more information on oplog size, see Oplog Size.

+ **Write Concern**
Delayed replica set members can acknowledge write operations issued with w: <number>. For write operations isued with w : "majority", however, delayed members must also be voting members (i.e. members[n].votes greater than 0) to acknowledge the "majority" write operation. Non-voting replica set members (i.e. members[n].votes is 0) cannot contribute to acknowledging write operations with majority write concern.

Delayed secondaries can return write acknowledgment no earlier than the configured slaveDelay.

+ **Sharding**
In sharded clusters, delayed members have limited utility when the balancer is enabled. Because delayed members replicate chunk migrations with a delay, the state of delayed members in a sharded cluster are not useful for recovering to a previous state of the sharded cluster if any migrations occur during the delay window.

+ **Example**
In the following 5-member replica set, the primary and all secondaries have copies of the data set. One member applies operations with a delay of 3600 seconds (one hour). This delayed member is also hidden and is a priority 0 member.

！[avatar](https://docs.mongodb.com/manual/_images/replica-set-delayed-member.bakedsvg.svg)

+ **Configuration**
A delayed member has its members[n].priority equal to 0, members[n].hidden equal to true, and its members[n].slaveDelay equal to the number of seconds of delay:
```
{
   "_id" : <num>,
   "host" : <hostname:port>,
   "priority" : 0,
   "slaveDelay" : <seconds>,
   "hidden" : true
}
```


## Replica Set Arbiter
In some circumstances (such as you have a primary and a secondary but cost constraints prohibit adding another secondary), you may choose to add an arbiter to your replica set. An arbiter does not have a copy of data set and cannot become a primary. However, an arbiter participates in elections for primary. An arbiter has exactly 1 election vote.

Changed in version 3.6: Starting in MongoDB 3.6, arbiters have priority 0. When you upgrade a replica set to MongoDB 3.6, if the existing configuration has an arbiter with priority 1, MongoDB 3.6 reconfigures the arbiter to have priority 0.

```
IMPORTANT
Do not run an arbiter on systems that also host the primary or the secondary members of the replica set.
```

+ **Example**
For example, in the following replica set with a 2 data bearing members (the primary and a secondary), an arbiter allows the set to have an odd number of votes to break a tie:

![avatar](https://docs.mongodb.com/manual/_images/replica-set-primary-with-secondary-and-arbiter.bakedsvg.svg)

+ **Read Concern majority and Three-Member PSA**
FOR 3-MEMBER PRIMARY-SECONDARY-ARBITER ARCHITECTURE*

If you have a three-member replica set with a primary-secondary-arbiter (PSA) architecture or a sharded cluster with a three-member PSA shards, the cache pressure will increase if any data bearing node is down and support for "majority" read concern is enabled.

To prevent the storage cache pressure from immobilizing a deployment with a three-member primary-secondary-arbiter (PSA) architecture, you can disable read concern “majority” starting in MongoDB 4.0.3 (and 3.6.1+). For more information, see Disable Read Concern Majority.

+ **Replica Set Protocol Version and Arbiter**
For the following MongoDB versions, pv1 increases the likelihood of w:1 rollbacks compared to pv0 (no longer supported in MongoDB 4.0+) for replica sets with arbiters:

+ MongoDB 3.4.1
+ MongoDB 3.4.0
+ MongoDB 3.2.11 or earlier

+ **Security**
    * *Authentication* 
        When running with authorization, arbiters exchange credentials with other members of the set to authenticate. MongoDB encrypts the authentication process, and the MongoDB authentication exchange is cryptographically secure.

        Because arbiters do not store data, they do not possess the internal table of user and role mappings used for authentication. Thus, the only way to log on to an arbiter with authorization active is to use the localhost exception.
    * *Communication*
        The only communication between <a href=""></a>rbiters and other set members are: votes during elections, heartbeats, and configuration data. These exchanges are not encrypted.

        However, if your MongoDB deployment uses TLS/SSL, MongoDB will encrypt all communication between replica set members. See Configure mongod and mongos for TLS/SSL for more information.

        As with all MongoDB components, run arbiters in trusted network environments.
